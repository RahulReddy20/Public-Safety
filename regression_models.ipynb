{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w_c9ZkQWcxhG",
        "outputId": "9a48416f-da65-4893-bf52-9491109b1f04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install category_encoders"
      ],
      "metadata": {
        "id": "FRYYHTFhh0Bn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8758c7ee-1839-4d20-b8bd-bab5e67b0bb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing collected packages: category_encoders\n",
            "Successfully installed category_encoders-2.6.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from category_encoders import TargetEncoder\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import r2_score, mean_absolute_error\n",
        "import joblib"
      ],
      "metadata": {
        "id": "NjxnFOfnc8jv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_VI8KcHIEXW6"
      },
      "outputs": [],
      "source": [
        "# Change the file path to your input file\n",
        "file_path = '/content/drive/My Drive/6301.501/df1WithTimeBin.csv'\n",
        "# column names required from input file\n",
        "columns_required = ['Day1 of the Week', 'Time Bin', 'Zip Code', 'Division', 'Sector', 'Incident_Score']\n",
        "df = pd.read_csv(file_path, usecols=columns_required)\n",
        "# columns from df that are required to be considered as features\n",
        "columns_considered = ['Day1 of the Week', 'Time Bin', 'Zip Code', 'Division', 'Sector']\n",
        "\n",
        "X = df[columns_considered]\n",
        "y = df['Incident_Score']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y.head(),\"\\n\", X.head())"
      ],
      "metadata": {
        "id": "hobjY_c1Yeh9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pipeline for 4 encoding types is created. comment the encoding types not required\n",
        "encodings = {\n",
        "    'one_hot': ColumnTransformer(transformers=[('cat', OneHotEncoder(handle_unknown='ignore'), columns_considered)]),\n",
        "    'label': 'label',\n",
        "    'target': 'target',\n",
        "    'frequency':'frequency'\n",
        "}"
      ],
      "metadata": {
        "id": "shzAUfU3W8b6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Onehotencoding (ignore this section)\n"
      ],
      "metadata": {
        "id": "P-D9q1vkDYw0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# preprocessor = ColumnTransformer(transformers=[('cat', OneHotEncoder(handle_unknown='ignore'), Colums_considered)])\n",
        "\n",
        "# X_transformed = preprocessor.fit_transform(df[Colums_considered])\n",
        "\n",
        "# X_transformed_df = pd.DataFrame(X_transformed.toarray(), columns=preprocessor.named_transformers_['cat'].get_feature_names_out(Colums_considered))\n",
        "\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X_transformed_df, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "a6irQZhCDLNj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Label Encoding (ignore this section)"
      ],
      "metadata": {
        "id": "4epTVHvHDe-3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# label_encoders = {col: LabelEncoder() for col in Colums_considered}\n",
        "\n",
        "# # Fit and transform the data to label encoding\n",
        "# for col, encoder in label_encoders.items():\n",
        "#     df[col] = encoder.fit_transform(df[col])\n",
        "\n",
        "# X = df[Colums_considered]\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "# print(X_train.head())\n",
        "# print(y_test.head())\n",
        "# print(y_train.head())"
      ],
      "metadata": {
        "id": "ODX8Gp0YDeBc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Target Encoding (ignore this section)"
      ],
      "metadata": {
        "id": "gHh4ndMvG6KC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from category_encoders import TargetEncoder\n",
        "# from sklearn.compose import ColumnTransformer\n",
        "\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# target_encoder = TargetEncoder(cols=Colums_considered)\n",
        "\n",
        "# # Fit the encoder on the training data and transform both the training and test data\n",
        "# X_train_encoded = target_encoder.fit_transform(X_train, y_train)\n",
        "# X_test_encoded = target_encoder.transform(X_test)\n",
        "\n",
        "# X_train = X_train_encoded\n",
        "# X_test = X_test_encoded\n",
        "\n",
        "# print(X_train.head())"
      ],
      "metadata": {
        "id": "fu8_tjPxG50g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Frequency/Count Encoding (ignore this section)"
      ],
      "metadata": {
        "id": "4qTAu9feJFVS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "# def frequency_encoding(df, column):\n",
        "#     freq = df[column].value_counts(normalize=True)\n",
        "#     df[column] = df[column].map(freq)\n",
        "#     return df\n",
        "\n",
        "# # Apply frequency encoding to the specified columns\n",
        "# for col in Colums_considered:\n",
        "#     X_train = frequency_encoding(X_train, col)\n",
        "#     X_test = frequency_encoding(X_test, col)"
      ],
      "metadata": {
        "id": "t0ulMVorJFBk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#pipeline"
      ],
      "metadata": {
        "id": "OxqS-3neJZZM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# pipeline for five regression models is created. comment the ones that are not required\n",
        "\n",
        "pipelines = {\n",
        "    'rf':make_pipeline(RandomForestRegressor(random_state=1234)),\n",
        "    'gb':make_pipeline(GradientBoostingRegressor(random_state=1234)),\n",
        "    # 'ridge':make_pipeline(Ridge(random_state=1234)),\n",
        "    # 'lasso':make_pipeline(Lasso(random_state=1234)),\n",
        "    # 'enet':make_pipeline(ElasticNet(random_state=1234))\n",
        "\n",
        "}\n",
        "\n",
        "hypergrid = {\n",
        "    'rf':{\n",
        "        'randomforestregressor__min_samples_split':[50],\n",
        "        'randomforestregressor__min_samples_leaf':[50]\n",
        "    # #     # 'randomforestregressor__min_samples_split':[2,4,6],\n",
        "    # #     # 'randomforestregressor__min_samples_leaf':[1,2,3]\n",
        "    },\n",
        "    'gb': {\n",
        "        'gradientboostingregressor__alpha': [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 0.99]\n",
        "    },\n",
        "    # 'ridge':{\n",
        "    #   'ridge__alpha':[0.001,0.005,0.01,0.05,0.1]\n",
        "    # },\n",
        "    # 'lasso':{\n",
        "    #   'lasso__alpha':[0.001,0.005,0.01,0.05,0.1,0.5,0.99]\n",
        "    # },\n",
        "    # 'enet':{\n",
        "    #     'elasticnet__alpha' : [0.001,0.005,0.01,0.05,0.1,0.5,0.99]\n",
        "    # }\n",
        "}"
      ],
      "metadata": {
        "id": "T398ImdxE5vM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Testing regression scores with kaggle datasets (ignore this section)"
      ],
      "metadata": {
        "id": "Dc6iqCv6xZY9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# file_path = '/content/drive/My Drive/6301.501/dataset_with_safety_scores.csv'\n",
        "# columns_required = ['Zip-Time-Percentage', 'Zipcode-Day-Percentage', 'Zipcode-Percentage', 'Incident_Score']\n",
        "# df = pd.read_csv(file_path, usecols=columns_required)\n",
        "\n",
        "# columns_considered = ['Zip-Time-Percentage', 'Zipcode-Day-Percentage', 'Zipcode-Percentage']\n",
        "# # Columns_considered = ['Day1 of the Week', 'Time Bin', 'Zip Code']\n",
        "# X = df[columns_considered]\n",
        "# y = df['Incident_Score']"
      ],
      "metadata": {
        "id": "7veA32LIK2PD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = pd.DataFrame()"
      ],
      "metadata": {
        "id": "ybVToq4c5C9N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def save_results(results, y_test, y_pred, model_name, encoding_name):\n",
        "    results[f'{model_name}_{encoding_name}_y_pred'] = y_pred\n",
        "    results[f'{model_name}_{encoding_name}_y_test'] = y_test\n",
        "\n",
        "\n",
        "def frequency_encoding(df, column):\n",
        "    freq = df[column].value_counts(normalize=True)\n",
        "    df[column] = df[column].map(freq)\n",
        "    return df\n",
        "\n",
        "\n",
        "# Loop through the encoding methods and models\n",
        "for encoding_name, encoder in encodings.items():\n",
        "\n",
        "    # Copy the original X data for each encoding iteration\n",
        "    X_encoded = X.copy()\n",
        "    # Encode the features\n",
        "    if encoder == 'label':\n",
        "        X_encoded = X.copy()\n",
        "        label_encoders = {col: LabelEncoder() for col in columns_considered}\n",
        "        for col, label_encoder in label_encoders.items():\n",
        "            X_encoded[col] = label_encoder.fit_transform(X[col])\n",
        "    elif encoder == 'target':\n",
        "        X_encoded = TargetEncoder(cols=columns_considered).fit_transform(X, y)\n",
        "    elif encoder == 'frequency':\n",
        "        for col in columns_considered:\n",
        "            X_encoded = frequency_encoding(X_encoded, col)\n",
        "    else:\n",
        "        X_encoded = encoder.fit_transform(X)\n",
        "        X_encoded = pd.DataFrame(X_encoded.toarray(), columns=encoder.named_transformers_['cat'].get_feature_names_out(columns_considered))\n",
        "\n",
        "    # Split the data\n",
        "    X_train, X_test_encoded, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)\n",
        "    X_train_original, X_test_original, _, y_test_original = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    if 'y_test' not in results.columns:\n",
        "        results = pd.DataFrame(X_test_original, columns=columns_considered)\n",
        "        results['y_test'] = y_test\n",
        "        results['y_test_original'] = y_test_original\n",
        "\n",
        "    # Loop through the models\n",
        "    for model_name, pipeline in pipelines.items():\n",
        "        model = GridSearchCV(pipeline, hypergrid[model_name], cv=10, n_jobs=-1)\n",
        "\n",
        "        # Fit the model\n",
        "        print(f'Starting training for {model_name} with {encoding_name} encoding...')\n",
        "        model.fit(X_train, y_train)\n",
        "        print(f'{model_name} has been successfully fit with {encoding_name} encoding.')\n",
        "\n",
        "        # Predict the results\n",
        "        y_pred = model.predict(X_test_encoded)\n",
        "\n",
        "        # Save the results to a CSV file\n",
        "        # save_results(results, y_test, y_pred, model_name, encoding_name)\n",
        "        # Print the results\n",
        "        print(f'{model_name} scores with {encoding_name} encoding - R2: {r2_score(y_test, y_pred)}  MAE: {mean_absolute_error(y_test, y_pred)}')\n",
        "        # temp_results = pd.DataFrame()\n",
        "        results[f'{model_name}_{encoding_name}_y_pred'] = y_pred\n",
        "        results[f'{model_name}_{encoding_name}_y_test'] = y_test\n",
        "\n",
        "# Save the final results to a CSV file\n",
        "results.to_csv('/content/drive/My Drive/6301.501/results.csv', index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wnAg7yRRdu2E",
        "outputId": "b45673a3-4ac9-42e4-901e-bc229996f39a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training for rf with label encoding...\n",
            "rf has been successfully fit with label encoding.\n",
            "rf scores with label encoding - R2: 0.012336007504987756  MAE: 18.411957455284842\n",
            "Starting training for gb with label encoding...\n",
            "gb has been successfully fit with label encoding.\n",
            "gb scores with label encoding - R2: 0.010191230675212215  MAE: 18.481882964834718\n",
            "Starting training for rf with target encoding...\n",
            "rf has been successfully fit with target encoding.\n",
            "rf scores with target encoding - R2: 0.012496432373384936  MAE: 18.41017037569183\n",
            "Starting training for gb with target encoding...\n",
            "gb has been successfully fit with target encoding.\n",
            "gb scores with target encoding - R2: 0.012713185834549834  MAE: 18.4236266924323\n",
            "Starting training for rf with frequency encoding...\n",
            "rf has been successfully fit with frequency encoding.\n",
            "rf scores with frequency encoding - R2: 0.012313031656951967  MAE: 18.412178722217615\n",
            "Starting training for gb with frequency encoding...\n",
            "gb has been successfully fit with frequency encoding.\n",
            "gb scores with frequency encoding - R2: 0.008937425495715523  MAE: 18.507071540208162\n"
          ]
        }
      ]
    }
  ]
}